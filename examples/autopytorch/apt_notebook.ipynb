{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using CAVE with AutoPyTorch\n",
    "\n",
    "AutoPyTorch aims at building a framework for automated neural-network-configuration. Currently it supports [BOHB](https://github.com/automl/HpBandSter) for hyperparameter search.\n",
    "CAVE integrates AutoPyTorch, building on it's function for further insights and visualizations.\n",
    "This notebook provides an exemplary pipeline for using CAVE on / with AutoPyTorch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will generate some AutoPyTorch-Output. You can use your own AutoPyTorch-routine here, we will use the openml-tasks, inspired by [AutoPyTorch's tutorial notebook](https://github.com/automl/Auto-PyTorch/blob/master/examples/basics/Auto-PyTorch%20Tutorial.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "log_dir = \"logs/apt-cave-notebook/\"\n",
    "shutil.rmtree(log_dir, ignore_errors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autoPyTorch import AutoNetClassification\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os as os\n",
    "import openml\n",
    "import json\n",
    "from ConfigSpace.read_and_write import json as pcs_json\n",
    "# Logging\n",
    "from autoPyTorch.components.metrics.additional_logs import *\n",
    "from autoPyTorch.pipeline.nodes import LogFunctionsSelector\n",
    "\n",
    "task = openml.tasks.get_task(task_id=31)\n",
    "\n",
    "X, y = task.get_X_and_y()\n",
    "ind_train, ind_test = task.get_train_test_split_indices()\n",
    "X_train, Y_train = X[ind_train], y[ind_train]\n",
    "X_test, Y_test = X[ind_test], y[ind_test]\n",
    "\n",
    "autopytorch = AutoNetClassification(config_preset=\"medium_cs\",\n",
    "                                    result_logger_dir=log_dir,\n",
    "                                    #log_every_n_datapoints=10,\n",
    "                                    additional_logs=[test_result.__name__,\n",
    "                                                     test_cross_entropy.__name__,\n",
    "                                                     test_balanced_accuracy.__name__],\n",
    "                                   )\n",
    "\n",
    "# Get data from the openml task \"Supervised Classification on credit-g (https://www.openml.org/t/31)\"\n",
    "task = openml.tasks.get_task(task_id=31)\n",
    "X, y = task.get_X_and_y()\n",
    "ind_train, ind_test = task.get_train_test_split_indices()\n",
    "X_train, Y_train = X[ind_train], y[ind_train]\n",
    "X_test, Y_test = X[ind_test], y[ind_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Equip autopytorch with additional logs\n",
    "gl = GradientLogger()\n",
    "lw_gl = LayerWiseGradientLogger()\n",
    "additional_logs = [gradient_max(gl), gradient_mean(gl), gradient_median(gl), gradient_std(gl),\n",
    "                   gradient_q10(gl), gradient_q25(gl), gradient_q75(gl), gradient_q90(gl),\n",
    "                   layer_wise_gradient_max(lw_gl), layer_wise_gradient_mean(lw_gl),\n",
    "                   layer_wise_gradient_median(lw_gl), layer_wise_gradient_std(lw_gl),\n",
    "                   layer_wise_gradient_q10(lw_gl), layer_wise_gradient_q25(lw_gl),\n",
    "                   layer_wise_gradient_q75(lw_gl), layer_wise_gradient_q90(lw_gl),\n",
    "                   gradient_norm()]\n",
    "\n",
    "for additional_log in additional_logs:\n",
    "    autopytorch.pipeline[LogFunctionsSelector.get_name()].add_log_function(name=type(additional_log).__name__,\n",
    "                                                                       log_function=additional_log)\n",
    "\n",
    "    #sampling_space[\"additional_logs\"].append(type(additional_log).__name__)\n",
    "\n",
    "autopytorch.pipeline[LogFunctionsSelector.get_name()].add_log_function(name=test_result.__name__, \n",
    "                                                                   log_function=test_result(autopytorch, X[ind_test], y[ind_test]))\n",
    "autopytorch.pipeline[LogFunctionsSelector.get_name()].add_log_function(name=test_cross_entropy.__name__,\n",
    "                                                                   log_function=test_cross_entropy(autopytorch, X[ind_test], y[ind_test]))\n",
    "autopytorch.pipeline[LogFunctionsSelector.get_name()].add_log_function(name=test_balanced_accuracy.__name__,\n",
    "                                                                   log_function=test_balanced_accuracy(autopytorch, X[ind_test], y[ind_test]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Box-Cox transformation can only be applied to strictly positive data\n",
      "Using yeo-johnson instead\n",
      "The Box-Cox transformation can only be applied to strictly positive data\n",
      "Using yeo-johnson instead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shuki/VirtualEnvs/CAVE_dev/lib/python3.6/site-packages/numpy/core/_methods.py:195: RuntimeWarning: overflow encountered in multiply\n",
      "  x = um.multiply(x, x, out=x)\n",
      "/home/shuki/VirtualEnvs/CAVE_dev/lib/python3.6/site-packages/sklearn/preprocessing/data.py:2863: RuntimeWarning: divide by zero encountered in log\n",
      "  loglike = -n_samples / 2 * np.log(x_trans.var())\n",
      "/home/shuki/VirtualEnvs/CAVE_dev/lib/python3.6/site-packages/numpy/core/_methods.py:195: RuntimeWarning: overflow encountered in multiply\n",
      "  x = um.multiply(x, x, out=x)\n",
      "/home/shuki/VirtualEnvs/CAVE_dev/lib/python3.6/site-packages/sklearn/preprocessing/data.py:2863: RuntimeWarning: divide by zero encountered in log\n",
      "  loglike = -n_samples / 2 * np.log(x_trans.var())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Box-Cox transformation can only be applied to strictly positive data\n",
      "Using yeo-johnson instead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shuki/VirtualEnvs/CAVE_dev/lib/python3.6/site-packages/numpy/core/_methods.py:195: RuntimeWarning: overflow encountered in multiply\n",
      "  x = um.multiply(x, x, out=x)\n",
      "/home/shuki/VirtualEnvs/CAVE_dev/lib/python3.6/site-packages/sklearn/preprocessing/data.py:2863: RuntimeWarning: divide by zero encountered in log\n",
      "  loglike = -n_samples / 2 * np.log(x_trans.var())\n",
      "/home/shuki/VirtualEnvs/CAVE_dev/lib/python3.6/site-packages/numpy/core/_methods.py:195: RuntimeWarning: overflow encountered in multiply\n",
      "  x = um.multiply(x, x, out=x)\n",
      "/home/shuki/VirtualEnvs/CAVE_dev/lib/python3.6/site-packages/sklearn/preprocessing/data.py:2863: RuntimeWarning: divide by zero encountered in log\n",
      "  loglike = -n_samples / 2 * np.log(x_trans.var())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Box-Cox transformation can only be applied to strictly positive data\n",
      "Using yeo-johnson instead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shuki/VirtualEnvs/CAVE_dev/lib/python3.6/site-packages/numpy/core/_methods.py:195: RuntimeWarning: overflow encountered in multiply\n",
      "  x = um.multiply(x, x, out=x)\n",
      "/home/shuki/VirtualEnvs/CAVE_dev/lib/python3.6/site-packages/sklearn/preprocessing/data.py:2863: RuntimeWarning: divide by zero encountered in log\n",
      "  loglike = -n_samples / 2 * np.log(x_trans.var())\n",
      "/home/shuki/VirtualEnvs/CAVE_dev/lib/python3.6/site-packages/numpy/core/_methods.py:195: RuntimeWarning: overflow encountered in multiply\n",
      "  x = um.multiply(x, x, out=x)\n",
      "/home/shuki/VirtualEnvs/CAVE_dev/lib/python3.6/site-packages/sklearn/preprocessing/data.py:2863: RuntimeWarning: divide by zero encountered in log\n",
      "  loglike = -n_samples / 2 * np.log(x_trans.var())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Box-Cox transformation can only be applied to strictly positive data\n",
      "Using yeo-johnson instead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shuki/VirtualEnvs/CAVE_dev/lib/python3.6/site-packages/numpy/core/_methods.py:195: RuntimeWarning: overflow encountered in multiply\n",
      "  x = um.multiply(x, x, out=x)\n",
      "/home/shuki/VirtualEnvs/CAVE_dev/lib/python3.6/site-packages/sklearn/preprocessing/data.py:2863: RuntimeWarning: divide by zero encountered in log\n",
      "  loglike = -n_samples / 2 * np.log(x_trans.var())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Box-Cox transformation can only be applied to strictly positive data\n",
      "Using yeo-johnson instead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process pynisher function call:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/shuki/VirtualEnvs/CAVE_dev/lib/python3.6/site-packages/pynisher/limit_function_call.py\", line 93, in subprocess_func\n",
      "    return_value = ((func(*args, **kwargs), 0))\n",
      "  File \"/home/shuki/Repos/Auto-PyTorch/autoPyTorch/core/worker.py\", line 124, in optimize_pipeline\n",
      "    raise e\n",
      "  File \"/home/shuki/Repos/Auto-PyTorch/autoPyTorch/core/worker.py\", line 118, in optimize_pipeline\n",
      "    refit=False, rescore=False, hyperparameter_config_id=config_id, dataset_info=self.dataset_info)\n",
      "  File \"/home/shuki/Repos/Auto-PyTorch/autoPyTorch/pipeline/base/pipeline.py\", line 60, in fit_pipeline\n",
      "    return self.root.fit_traverse(**kwargs)\n",
      "  File \"/home/shuki/Repos/Auto-PyTorch/autoPyTorch/pipeline/base/node.py\", line 115, in fit_traverse\n",
      "    node.fit_output = node.fit(**required_kwargs)\n",
      "  File \"/home/shuki/Repos/Auto-PyTorch/autoPyTorch/pipeline/nodes/cross_validation.py\", line 108, in fit\n",
      "    result = self.sub_pipeline.fit_pipeline(X=X, Y=Y, **sub_pipeline_kwargs)\n",
      "  File \"/home/shuki/Repos/Auto-PyTorch/autoPyTorch/pipeline/base/pipeline.py\", line 60, in fit_pipeline\n",
      "    return self.root.fit_traverse(**kwargs)\n",
      "  File \"/home/shuki/Repos/Auto-PyTorch/autoPyTorch/pipeline/base/node.py\", line 115, in fit_traverse\n",
      "    node.fit_output = node.fit(**required_kwargs)\n",
      "  File \"/home/shuki/Repos/Auto-PyTorch/autoPyTorch/pipeline/nodes/train_node.py\", line 122, in fit\n",
      "    optimize_metric_results, train_loss, stop_training = trainer.train(epoch + 1, train_loader)\n",
      "  File \"/home/shuki/Repos/Auto-PyTorch/autoPyTorch/components/training/trainer.py\", line 133, in train\n",
      "    outputs = self.model(data)\n",
      "  File \"/home/shuki/VirtualEnvs/CAVE_dev/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 541, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/shuki/Repos/Auto-PyTorch/autoPyTorch/components/networks/base_net.py\", line 67, in forward\n",
      "    return super(BaseFeatureNet, self).forward(x)\n",
      "  File \"/home/shuki/Repos/Auto-PyTorch/autoPyTorch/components/networks/base_net.py\", line 38, in forward\n",
      "    x = self.layers(x)\n",
      "  File \"/home/shuki/VirtualEnvs/CAVE_dev/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 541, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/shuki/VirtualEnvs/CAVE_dev/lib/python3.6/site-packages/torch/nn/modules/container.py\", line 92, in forward\n",
      "    input = module(input)\n",
      "  File \"/home/shuki/VirtualEnvs/CAVE_dev/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 541, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/shuki/VirtualEnvs/CAVE_dev/lib/python3.6/site-packages/torch/nn/modules/container.py\", line 92, in forward\n",
      "    input = module(input)\n",
      "  File \"/home/shuki/VirtualEnvs/CAVE_dev/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 541, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/shuki/Repos/Auto-PyTorch/autoPyTorch/components/networks/feature/resnet.py\", line 169, in forward\n",
      "    x = self.start_norm(x)\n",
      "  File \"/home/shuki/VirtualEnvs/CAVE_dev/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 541, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/shuki/VirtualEnvs/CAVE_dev/lib/python3.6/site-packages/torch/nn/modules/container.py\", line 92, in forward\n",
      "    input = module(input)\n",
      "  File \"/home/shuki/VirtualEnvs/CAVE_dev/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 541, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/shuki/VirtualEnvs/CAVE_dev/lib/python3.6/site-packages/torch/nn/modules/batchnorm.py\", line 81, in forward\n",
      "    exponential_average_factor, self.eps)\n",
      "  File \"/home/shuki/VirtualEnvs/CAVE_dev/lib/python3.6/site-packages/torch/nn/functional.py\", line 1666, in batch_norm\n",
      "    raise ValueError('Expected more than 1 value per channel when training, got input size {}'.format(size))\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 34])\n",
      "14:13:19 job (3, 0, 5) failed with exception\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/shuki/VirtualEnvs/CAVE_dev/lib/python3.6/site-packages/hpbandster-0.7.4-py3.6.egg/hpbandster/core/worker.py\", line 206, in start_computation\n",
      "    result = {'result': self.compute(*args, config_id=id, **kwargs),\n",
      "  File \"/home/shuki/Repos/Auto-PyTorch/autoPyTorch/core/worker.py\", line 86, in compute\n",
      "    raise Exception(\"Exception in train pipeline. Took \" + str((time.time()-start_time)) + \" seconds with budget \" + str(budget))\n",
      "Exception: Exception in train pipeline. Took 2.988280773162842 seconds with budget 22.22222222222222\n",
      "\n",
      "/home/shuki/VirtualEnvs/CAVE_dev/lib/python3.6/site-packages/numpy/core/_methods.py:195: RuntimeWarning: overflow encountered in multiply\n",
      "  x = um.multiply(x, x, out=x)\n",
      "/home/shuki/VirtualEnvs/CAVE_dev/lib/python3.6/site-packages/sklearn/preprocessing/data.py:2863: RuntimeWarning: divide by zero encountered in log\n",
      "  loglike = -n_samples / 2 * np.log(x_trans.var())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Box-Cox transformation can only be applied to strictly positive data\n",
      "Using yeo-johnson instead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shuki/VirtualEnvs/CAVE_dev/lib/python3.6/site-packages/numpy/core/_methods.py:195: RuntimeWarning: overflow encountered in multiply\n",
      "  x = um.multiply(x, x, out=x)\n",
      "/home/shuki/VirtualEnvs/CAVE_dev/lib/python3.6/site-packages/sklearn/preprocessing/data.py:2863: RuntimeWarning: divide by zero encountered in log\n",
      "  loglike = -n_samples / 2 * np.log(x_trans.var())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Box-Cox transformation can only be applied to strictly positive data\n",
      "Using yeo-johnson instead\n",
      "The Box-Cox transformation can only be applied to strictly positive data\n",
      "Using yeo-johnson instead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shuki/VirtualEnvs/CAVE_dev/lib/python3.6/site-packages/numpy/core/_methods.py:195: RuntimeWarning: overflow encountered in multiply\n",
      "  x = um.multiply(x, x, out=x)\n",
      "/home/shuki/VirtualEnvs/CAVE_dev/lib/python3.6/site-packages/sklearn/preprocessing/data.py:2863: RuntimeWarning: divide by zero encountered in log\n",
      "  loglike = -n_samples / 2 * np.log(x_trans.var())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Box-Cox transformation can only be applied to strictly positive data\n",
      "Using yeo-johnson instead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shuki/VirtualEnvs/CAVE_dev/lib/python3.6/site-packages/numpy/core/_methods.py:195: RuntimeWarning: overflow encountered in multiply\n",
      "  x = um.multiply(x, x, out=x)\n",
      "/home/shuki/VirtualEnvs/CAVE_dev/lib/python3.6/site-packages/sklearn/preprocessing/data.py:2863: RuntimeWarning: divide by zero encountered in log\n",
      "  loglike = -n_samples / 2 * np.log(x_trans.var())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Box-Cox transformation can only be applied to strictly positive data\n",
      "Using yeo-johnson instead\n",
      "The Box-Cox transformation can only be applied to strictly positive data\n",
      "Using yeo-johnson instead\n",
      "The Box-Cox transformation can only be applied to strictly positive data\n",
      "Using yeo-johnson instead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shuki/VirtualEnvs/CAVE_dev/lib/python3.6/site-packages/numpy/core/_methods.py:195: RuntimeWarning: overflow encountered in multiply\n",
      "  x = um.multiply(x, x, out=x)\n",
      "/home/shuki/VirtualEnvs/CAVE_dev/lib/python3.6/site-packages/sklearn/preprocessing/data.py:2863: RuntimeWarning: divide by zero encountered in log\n",
      "  loglike = -n_samples / 2 * np.log(x_trans.var())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Box-Cox transformation can only be applied to strictly positive data\n",
      "Using yeo-johnson instead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shuki/VirtualEnvs/CAVE_dev/lib/python3.6/site-packages/numpy/core/_methods.py:195: RuntimeWarning: overflow encountered in multiply\n",
      "  x = um.multiply(x, x, out=x)\n",
      "/home/shuki/VirtualEnvs/CAVE_dev/lib/python3.6/site-packages/sklearn/preprocessing/data.py:2863: RuntimeWarning: divide by zero encountered in log\n",
      "  loglike = -n_samples / 2 * np.log(x_trans.var())\n",
      "/home/shuki/VirtualEnvs/CAVE_dev/lib/python3.6/site-packages/numpy/core/_methods.py:195: RuntimeWarning: overflow encountered in multiply\n",
      "  x = um.multiply(x, x, out=x)\n",
      "/home/shuki/VirtualEnvs/CAVE_dev/lib/python3.6/site-packages/sklearn/preprocessing/data.py:2863: RuntimeWarning: divide by zero encountered in log\n",
      "  loglike = -n_samples / 2 * np.log(x_trans.var())\n"
     ]
    }
   ],
   "source": [
    "# Fit to find an incumbent configuration with BOHB\n",
    "results_fit = autopytorch.fit(X_train=X_train,\n",
    "                              Y_train=Y_train,\n",
    "                              validation_split=0.3,\n",
    "                              max_runtime=5000,\n",
    "                              min_budget=20,\n",
    "                              max_budget=200,\n",
    "                              refit=True,\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Save fit results as json\n",
    "with open(os.path.join(log_dir, \"results_fit.json\"), \"w\") as f:\n",
    "    json.dump(results_fit, f, indent=2)\n",
    "    \n",
    "# Also necessary information (can be migrated either to CAVE or (preferably) to autopytorch)\n",
    "with open(os.path.join(log_dir, 'configspace.json'), 'w') as f:\n",
    "    f.write(pcs_json.write(autopytorch.get_hyperparameter_search_space(X_train=X_train,\n",
    "                                                                   Y_train=Y_train)))\n",
    "with open(os.path.join(log_dir, 'autonet_config.json'), 'w') as f:\n",
    "    json.dump(autopytorch.get_current_autonet_config(), f, indent=2)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then spin up CAVE and hand it the output, as well as the autonet-instance. That way, CAVE can refit the incumbents and we can investigate the evolution of the network a bit closer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from cave.cavefacade import CAVE\n",
    "\n",
    "cave_output_dir = \"cave_output\"\n",
    "\n",
    "autopytorch.update_autonet_config(autonet_config=dict([('result_logger_dir', cave_output_dir)]))\n",
    "\n",
    "# The information in the autonet-bundle needs to be logged and loaded eventually (or all necessary logging reliably triggered in apt itself)\n",
    "autonet_bundle = {'autopytorch': autopytorch,\n",
    "                  'X_train': X_train,\n",
    "                  'Y_train': Y_train,\n",
    "                 }\n",
    "\n",
    "cave = CAVE([log_dir],        # List of folders holding results\n",
    "            cave_output_dir,  # Output directory\n",
    "            ['.'],            # Target Algorithm Directory (only relevant for SMAC)\n",
    "            file_format=\"APT\",\n",
    "            autopytorch=autonet_bundle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q: should CAVE even get an autonet-instance? is all relevant information saved with info about the autonet-instance? would be nicer if there simply was some sort of scenario-file (which is partly/mostly covered by the results-dump)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cave.apt_overview()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other analyzers also run on the APT-data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cave.overview_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cave.compare_default_incumbent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cave.apt_tensorboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cave.cost_over_time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CAVE_dev",
   "language": "python",
   "name": "cave_dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
